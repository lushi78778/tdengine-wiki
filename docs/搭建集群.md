# 搭建集群
> TDengine 采用虚拟节点技术，将一个节点虚拟化为多个虚拟节点，以实现负载均衡。

> TDengine可以将多个节点上的虚拟节点组成虚拟节点组，通过多副本机制，以保证供系统的高可用。

> 本文讲述使用 YAML 文件创建 TDengine 集群，与 Kubernetes 环境下 TDengine 的常用操作。
## 虚拟机搭建
虚拟化平台使用Hyper-V，参考网站：[Windows 10 上的 Hyper-V](https://learn.microsoft.com/zh-cn/virtualization/hyper-v-on-windows/)<br>
如果使用物理集群（虚拟机多开），下面仅需配置涉及部分。
### CentOS相关
镜像地址：https://mirrors.tuna.tsinghua.edu.cn/centos/7.9.2009/isos/x86_64/
```text
[root@172 yum.repos.d]# cat /etc/redhat-release
CentOS Linux release 7.9.2009 (Core)
```
### 修改yum源为阿里云yum源
```bash
# 备份原来的yum文件
mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo_bak
# 下载阿里云的 CentOS-Base.repo 到/etc/yum.repos.d/
wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
# 或
curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
# 清空原本yum缓存
yum clean all
# 生成新的阿里云的yum缓存，加速下载预热数据
yum makecache
```
### 时间同步
```bash
# 启动时间同步服务
systemctl start chronyd
# 开机启动时间同步
systemctl enable chronyd
```
### 防火墙
```bash
# kubernetes和docker会产生很多iptables规则，这些规则会和系统规则混淆，直接关闭系统规则
# 关闭防火墙
systemctl stop firewalld
# 禁用防火墙
systemctl disable firewalld
# centos6版本是iptables，centos7是firewalld
# 关闭防火墙
systemctl stop iptables
# 禁用防火墙
systemctl disable iptables
```
### 禁用SELINUX
```bash
# 编辑/etc/selinux/config文件，修改SELINUX的值为disabled
SELINUX=disabled
```
### 禁用swap
```bash
# 打开/etc/fstab，注释掉swap分区所在的行
# /dev/mapper/centos_172-swap swap                    swap    defaults        0 0
```
### 安装docker
```bash
yum install docker-ce
# 修改配置文件
mkdir /etc/docker

cat > /etc/docker/daemon.json <<EOF
{
    "exec-opts": ["native.cgroupdriver=systemd"],
    "registry-mirrors": ["https://kn0t2bca.mirror.aliyuncs.com"]
}
EOF

systemctl restart docker
systemctl enable docker
```
### 修改linux内核参数
```bash
# 添加网桥过滤和地址转发功能
# 编辑/etc/sysctl.d/kubernetes.conf文件，添加如下配置
net.bridge.bridge-nf-call-ip6tables =1
net.bridge.bridge-nf-call-iptables =1
net.ipv4.ip_forward = 1
#修改完后重新加载配置
sysctl -p
#加载网桥过滤模块
modprobe br_netfilter
#查看网桥过滤模块是否加载成功
lsmod | grep br_netfilter
```
### 配置ipvs功能
```bash
# 安装ipset和ipvsadm模块
yum install ipset ipvsadm -y

# 添加需要加载的模块写入脚本文件
cat > /etc/sysconfig/modules/ipvs.modules <<EOF
#! /bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF
# 为脚本文件添加执行权限
chmod +x /etc/sysconfig/modules/ipvs.modules
# 执行脚本文件
/bin/bash /etc/sysconfig/modules/ipvs.modules
# 查看对应的模块是否加载成功
lsmod | grep -e ip_vs -e nf_conntrack_ipv4
```
### 安装kubeadm、kubelet和kubectl
```bash
# 指定版本号
yum install --setopt=obsoletes=0 -y kubelet-1.18.17 kubeadm-1.18.17 kubectl-1.18.17
# 修改"/etc/sysconfig/kubelet"文件
KUBELET_CGROUP_ARGS="--cgroup-driver=systemd"
KUBE_PROXY_MODE="ipvs"
systemctl enable kubelet
```
### 准备集群镜像
```bash
# 所需镜像查看
kubeadm config images list
```

> 我这里的<br>
>  k8s.gcr.io/kube-apiserver:v1.18.17<br>
> k8s.gcr.io/kube-controller-manager:v1.18.17<br>
> k8s.gcr.io/kube-scheduler:v1.18.17<br>
> k8s.gcr.io/kube-proxy:v1.18.17<br>
> k8s.gcr.io/pause:3.2<br>
> k8s.gcr.io/etcd:3.4.3-0<br>
> k8s.gcr.io/coredns:1.6.7<br>

```bash
# 一起复制没问题的
docker pull registry.aliyuncs.com/google_containers/kube-apiserver:v1.18.17
docker tag registry.aliyuncs.com/google_containers/kube-apiserver:v1.18.17 k8s.gcr.io/kube-apiserver:v1.18.17
docker rmi registry.aliyuncs.com/google_containers/kube-apiserver:v1.18.17

docker pull registry.aliyuncs.com/google_containers/kube-controller-manager:v1.18.17
docker tag registry.aliyuncs.com/google_containers/kube-controller-manager:v1.18.17 k8s.gcr.io/kube-controller-manager:v1.18.17
docker rmi registry.aliyuncs.com/google_containers/kube-controller-manager:v1.18.17

docker pull registry.aliyuncs.com/google_containers/kube-scheduler:v1.18.17
docker tag registry.aliyuncs.com/google_containers/kube-scheduler:v1.18.17 k8s.gcr.io/kube-scheduler:v1.18.17
docker rmi registry.aliyuncs.com/google_containers/kube-scheduler:v1.18.17

docker pull registry.aliyuncs.com/google_containers/kube-proxy:v1.18.17
docker tag registry.aliyuncs.com/google_containers/kube-proxy:v1.18.17 k8s.gcr.io/kube-proxy:v1.18.17
docker rmi registry.aliyuncs.com/google_containers/kube-proxy:v1.18.17

docker pull registry.aliyuncs.com/google_containers/pause:3.2
docker tag registry.aliyuncs.com/google_containers/pause:3.2 k8s.gcr.io/pause:3.2
docker rmi registry.aliyuncs.com/google_containers/pause:3.2

docker pull registry.aliyuncs.com/google_containers/etcd:3.4.3-0
docker tag registry.aliyuncs.com/google_containers/etcd:3.4.3-0 k8s.gcr.io/etcd:3.4.3-0
docker rmi registry.aliyuncs.com/google_containers/etcd:3.4.3-0

docker pull registry.aliyuncs.com/google_containers/coredns:1.6.7
docker tag registry.aliyuncs.com/google_containers/coredns:1.6.7 k8s.gcr.io/coredns:1.6.7
docker rmi registry.aliyuncs.com/google_containers/coredns:1.6.7
```
### ip静态化
#### 概述
Hyper-V自带一个不能删除的Default Switch虚拟交换机，虚拟机使用该网络可以自动获取IP直接上网。但这个网络的网关地址每次重启后都会改变，所以你无法在虚拟机上设置固定IP用于宿主机SSH访问。
<br>
微软说明：每次主机重启后Hyper-V会自动找一个未使用的网络然后修改Default Switch的网络地址。
<br>
方案是用虚拟机第一块网卡连接Default Switch自动获得IP和DNS上外网，用第二块网卡设置内部固定IP地址用于宿主机或其它虚拟机SSH连接。创建内部虚拟交换网络vEthernet (内部交换机)
#### 内部使用的虚拟交换机的地址
然后到Windows的“网络连接”里把vEthernet (内部交换机)的IP设为固定IP，比如192.168.3.1。这样设置也决定了192.168.3.x就是以后虚拟机的网段（网段需要按照实际情况设置）
#### 为虚拟机添加新网卡
在虚拟机上新增加一个网卡，加上原来的网卡，虚拟机就有两块网卡。然后将第一块网络适配器的虚拟交换机选为Default Switch，第二块选择前面新建的vEthernet (内部交换机)
#### 虚拟机内设置两块网卡的网络配置
##### 配置eth0
虚拟机启动后编辑/etc/sysconfig/network-scripts/ifcfg-eth0，把BOOTPROTO改为dhcp，ONBOOT改为yes

```text
TYPE="Ethernet"
PROXY_METHOD="none"
BROWSER_ONLY="no"
BOOTPROTO="dhcp"
DEFROUTE="yes"
IPV4_FAILURE_FATAL="no"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
IPV6_DEFROUTE="yes"
IPV6_FAILURE_FATAL="no"
IPV6_ADDR_GEN_MODE="stable-privacy"
NAME="eth0"
UUID="11faf1b5-2d11-4459-b85e-f8d1df00faeb"
DEVICE="eth0"
ONBOOT="yes"
```

##### 配置eth1
如果创建虚拟机时就加了一个新网卡，则安装Centos后里面应该已经有/etc/sysconfig/network-scripts/ifcfg-eth1配置文件，如果是安装操作系统之后才新增网卡的，则可以通过以下命令从/etc/sysconfig/network-scripts/ifcfg-eth0拷贝一份修改
```bash
cp /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth1
```
修改重点是把BOOTPROTO设成static；把NAME和DEVICE改为eth1；ONBOOT还是yes；记得删除UUID那行（不能和eth0相同）。最后就是加上IPADDR=192.168.3.2和NETMASK=255.255.255.0（注意：IP必须与vEthernet (内部交换机)一个网段，不需要设置GATEWAY）
```text
TYPE="Ethernet"
PROXY_METHOD="none"
BROWSER_ONLY="no"
BOOTPROTO="static"
DEFROUTE="yes"
IPV4_FAILURE_FATAL="no"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
IPV6_DEFROUTE="yes"
IPV6_FAILURE_FATAL="no"
IPV6_ADDR_GEN_MODE="stable-privacy"
NAME="eth1"
DEVICE="eth1"
ONBOOT="yes"
IPADDR=192.168.3.2
NETMASK=255.255.255.0
```
#### 重启网络
```bash
/etc/init.d/network restart     
```
### 多开虚拟机
Hyper-V快速克隆创建虚拟机，先导出后导入。导入虚拟机时，记得选择复制虚拟机
```bash
# 改ip参数
vim /etc/sysconfig/network-scripts/ifcfg-eth1
# 改主机名字
sudo hostnamectl set-hostname master
```
没事加个检查点，别玩砸了~
## 集群手动部署
### 下载安装TDengine
在所有物理节点安装 TDengine，且版本必须是一致的，但不要启动 taosd。第一个物理节点（master.mshome.net:6030）直接创建新集群，后续物理节点则输入master.mshome.net:6030。
```bash
# 下载安装包
cd /opt
curl -O https://www.taosdata.com/assets-download/3.0/TDengine-server-3.0.1.8-Linux-x64.rpm
curl -O https://www.taosdata.com/assets-download/3.0/taosTools-2.3.0-Linux-x64.rpm
# 安装
sudo rpm -ivh TDengine-server-3.0.1.8-Linux-x64.rpm
sudo rpm -ivh taosTools-2.3.0-Linux-x64.rpm
```
### 修改配置文件
192.168.3.2 `vim /etc/taos/taos.cfg`
```text
# The end point of the first dnode in the cluster to be connected to when this dnode or a TDengine CLI `taos` is started
firstEp                   master.mshome.net:6030

# The FQDN of the host on which this dnode will be started. It can be IP address
fqdn                      master.mshome.net

# The port for external access after this dnode is started
serverPort                6030

# The interval of this dnode reporting status to mnode, [1..10] seconds
statusInterval            1

# system time zone
timezone                  UTC-8

# system locale
locale                    en_US.UTF-8

# system charset
charset                   UTF-8
```
192.168.3.3<br>
fqdn                      node1.mshome.net<br>
192.168.3.4<br>
fqdn                      node2.mshome.net<br>
### TDengine 的服务进程相关命令
```bash
# 启动 TDengine 的服务进程
systemctl start taosd
# 检查服务是否正常工作
systemctl status taosd
# 重启服务进程
systemctl restart taosd
```
### 添加数据节点到集群中
启动第一个数据节点（master.mshome.net），然后执行 taos，启动 TDengine CLI，在其中执行命令 “SHOW DNODES”，可以看到刚启动的数据节点的 End Point 是：master.mshome.net:6030，就是这个新集群的 firstEp
```bash
# 在相应数据节点，使用 CLI 程序 taos，登录进 TDengine 系统，执行命令
CREATE DNODE "fqdn:6030";
# 查看新节点是否被成功加入
SHOW DNODES;
```
加入成功会显示
```text
     id      |            endpoint            | vnodes | support_vnodes |   status   |       create_time       |              note              |
=================================================================================================================================================
           1 | master.mshome.net:6030         |      2 |              8 | ready      | 2022-11-29 17:08:41.756 |                                |
           2 | node1.mshome.net:6030          |      0 |              8 | ready      | 2022-11-29 17:26:08.134 |                                |
           3 | node2.mshome.net:6030          |      0 |              8 | ready      | 2022-11-29 17:26:50.939 |                                |
Query OK, 3 row(s) in set (0.002977s)
```
## Kubernetes 上部署 TDengine 集群
导入新虚拟机，IP：192.168.3.5（k-master）192.168.3.6（k-node）
### 集群初始化
```bash
# 只在master节点上执行
sudo hostnamectl set-hostname k-master
# 镜像没问题的话
kubeadm init \
    --kubernetes-version=v1.18.17 \
    --pod-network-cidr=10.244.0.0/16 \
    --service-cidr=10.96.0.0/12 \
    --apiserver-advertise-address=192.168.3.5     #这里的IP地址需要修改为自己的master的IP地址
# 也可以指定镜像源为阿里云的镜像源
kubeadm init \
    --image-repository registry.aliyuncs.com/google_containers \
    --kubernetes-version=v1.18.17 \
    --pod-network-cidr=10.244.0.0/16 \
    --service-cidr=10.96.0.0/12 \
    --apiserver-advertise-address=192.168.3.5     #这里的IP地址需要修改为自己的master的IP地址
    
# 所有机器都要执行,不执行的无法使用kubectl命令
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# node节点上执行
sudo hostnamectl set-hostname k-node
# master节点运行成功，会输出一段shell脚本，类似如下
kubeadm join 192.168.3.5:6443 --token 6pe70i.aes1libbwfu4f9a8 \
    --discovery-token-ca-cert-hash sha256:5d2ffc559b8247637f5da00d7b00a93163229f7c1a0b226c77148c78e8a64d68
```
### 安装网络插件
kubernetes支持的网络插件很多，如flannel，calico，canal等等，选一种。
```bash

```
### 创建配置文件 taosd-service.yaml
```text
apiVersion: v1
kind: Service
metadata:
  name: "taosd"
  labels:
    app: "tdengine"
spec:
  ports:
    - name: tcp6030
      protocol: "TCP"
      port: 6030
    - name: tcp6041
      protocol: "TCP"
      port: 6041
  selector:
    app: "tdengine"
```
### 创建配置文件 taosd-service.yaml
```text
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: "tdengine"
  labels:
    app: "tdengine"
spec:
  serviceName: "taosd"
  replicas: 3
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: "tdengine"
  template:
    metadata:
      name: "tdengine"
      labels:
        app: "tdengine"
    spec:
      containers:
        - name: "tdengine"
          image: "tdengine/tdengine:3.0.0.0"
          imagePullPolicy: "IfNotPresent"
          ports:
            - name: tcp6030
              protocol: "TCP"
              containerPort: 6030
            - name: tcp6041
              protocol: "TCP"
              containerPort: 6041
          env:
            # POD_NAME for FQDN config
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            # SERVICE_NAME and NAMESPACE for fqdn resolve
            - name: SERVICE_NAME
              value: "taosd"
            - name: STS_NAME
              value: "tdengine"
            - name: STS_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            # TZ for timezone settings, we recommend to always set it.
            - name: TZ
              value: "Asia/Shanghai"
            # TAOS_ prefix will configured in taos.cfg, strip prefix and camelCase.
            - name: TAOS_SERVER_PORT
              value: "6030"
            # Must set if you want a cluster.
            - name: TAOS_FIRST_EP
              value: "$(STS_NAME)-0.$(SERVICE_NAME).$(STS_NAMESPACE).svc.cluster.local:$(TAOS_SERVER_PORT)"
            # TAOS_FQND should always be setted in k8s env.
            - name: TAOS_FQDN
              value: "$(POD_NAME).$(SERVICE_NAME).$(STS_NAMESPACE).svc.cluster.local"
          volumeMounts:
            - name: taosdata
              mountPath: /var/lib/taos
          readinessProbe:
            exec:
              command:
                - taos-check
            initialDelaySeconds: 5
            timeoutSeconds: 5000
          livenessProbe:
            exec:
              command:
                - taos-check
            initialDelaySeconds: 15
            periodSeconds: 20
  volumeClaimTemplates:
    - metadata:
        name: taosdata
      spec:
        accessModes:
          - "ReadWriteOnce"
        storageClassName: "standard"
        resources:
          requests:
            storage: "10Gi"
```